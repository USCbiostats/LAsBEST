---
title: "ChatGPT & R"
author: "Katelyn Queen"
date: "2023-07-17"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## ChatGPT

ChatGPT is an artificial intelligence model by OpenAI. Here's what they have to say about it: "We’ve trained a model called ChatGPT which interacts in a conversational way. The dialogue format makes it possible for ChatGPT to answer followup questions, admit its mistakes, challenge incorrect premises, and reject inappropriate requests."

Many other chat bots already exist and more are being released, however, according to an analysis by Swiss bank UBS, ChatGPT is the fastest-growing app of all time, reaching 100 million users just two months after it's release.

There are many ways to interface chatGPT with R. Today we will use the "gptstudio" package to use it as an RStudio addin.

```{r}

if (!require(gptstudio)) {install.packages("gptstudio"); library(gptstudio)}

```

Once the package is installed click the "Addins" button and option "ChatGPT". The console will then prompt you with the following:   
! OPENAI_API_KEY is not set.  
Do you want to set the OPENAI_API_KEY for this session?   
Type the number to set the OPENAI and you will be asked to enter your ChatGPT API key.

To get an API key, create a ChatGPT account at https://beta.openai.com/signup. Then go to your account settings, "View API Keys" and click "Create new secret key". Paste your created key into the console. Then the ChatGPT window should launch in the Viewer pane.

This version of ChatGPT does not have real-time information available. It will only assist with R programming.

## Titanic

Let's use ChatGPT to do an analysis on the survival of passengers from the Titanic. There is an example dataset "Titanic", which contains "information on the fate of passengers on the fatal maiden voyage of the ocean liner ‘Titanic’, summarized according to economic status (class), sex, age and survival."

The package "titanic" has this data in a long format, making it easier to use for modelling.

First, let's download and look at the structure of the training data.

```{r}

if (!require(titanic)) {install.packages("titanic"); library(titanic)}

str(titanic_train)

```

Say now that we want to look at the distribution of these classes of the passengers but don't know how. Let's ask ChatGPT. Start simple - "How do I look at the frequencies of passenger classes on the titanic?"

```{r}

class_freq <- table(titanic_train$Pclass)
class_freq


```

Now let's do a visualization of the same data! - "How do I look at the distribution of passenger classes on the titanic?"

```{r}

library(ggplot2)

# Create the bar plot
ggplot(data = titanic_train, aes(x = Pclass)) +
  geom_bar(fill = "steelblue") +
  labs(title = "Distribution of Passenger Classes on the Titanic",
       x = "Passenger Class",
       y = "Frequency")

```

What if I want to add the counts from the table to bars? - "How do I add the class counts to the graph?"

```{r}

# Create a summary table of passenger class frequencies
class_freq <- table(titanic_train$Pclass)

# Create a bar plot with class counts
ggplot(titanic_train, aes(x = Pclass)) +
  geom_bar() +
  geom_text(stat = "count", aes(label = after_stat(count)), vjust = -0.5) +
  labs(x = "Passenger Class", y = "Count")

```



Now let's look at if passenger class is related to survival. Let's start with a visualization. - "How do I look at the distribution of passenger classes on the titanic by survival status?"

```{r}

titanic_train$Survived <- as.factor(titanic_train$Survived)

# Create a stacked bar plot of passenger class distribution by survival status
ggplot(titanic_train, aes(x = Pclass, fill = Survived)) +
  geom_bar() +
  labs(x = "Passenger Class", y = "Count", fill = "Survived") +
  scale_fill_manual(values = c("red", "green"), labels = c("No", "Yes"))

```

Those colors are a little bright. Let's change the colors to something a little darker and add a title. - "Change the fill colors to dark red and dark green and add a title."

```{r}

# Create a stacked bar plot of passenger class distribution by survival status with title
ggplot(titanic_train, aes(x = Pclass, fill = Survived)) +
  geom_bar() +
  labs(x = "Passenger Class", y = "Count", fill = "Survived") +
  scale_fill_manual(values = c("#8B0000", "#006400"), labels = c("No", "Yes")) +
  ggtitle("Distribution of Passenger Classes on the Titanic by Survival Status")

```

Finally, let's add the count values for each class and survival status. - "Add count values to the plot"

```{r}
# Create a summary table of passenger class and survival status frequencies
class_survival_freq <- table(titanic_train$Pclass, titanic_train$Survived)

# Convert the summary table to a data frame
class_survival_df <- as.data.frame(class_survival_freq)

# Rename the columns for clarity
colnames(class_survival_df) <- c("Pclass", "Survived", "Count")

# Create a stacked bar plot of passenger class distribution by survival status with count values
ggplot(class_survival_df, aes(x = Pclass, y = Count, fill = Survived)) +
  geom_bar(stat = "identity", position = "stack") +
  geom_text(aes(label = Count), position = position_stack(vjust = 0.5), color = "black", size = 3) +
  labs(x = "Passenger Class", y = "Count", fill = "Survived") +
  scale_fill_manual(values = c("#8B0000", "#006400"), labels = c("No", "Yes")) +
  ggtitle("Distribution of Passenger Classes on the Titanic by Survival Status")


```


Now let's test if there is a statistically significant difference in survival rates by passenger class - "How do I test for a difference in survival rates on the Titanic by passenger class?"

```{r}

# Perform the chi-square test
chi_square_test <- chisq.test(titanic_train$Survived, titanic_train$Pclass)

# Display the test results
chi_square_test

```

There is a difference! But a chi-square test doesn't identify directionality, just that there is a difference. Let's write a model for this relationship - "How do I model the difference in survival rates on the Titanic by passenger class?"

```{r}

# Fit the logistic regression model
model <- glm(Survived ~ Pclass, data = titanic_train, family = binomial())

# Print the model summary
summary(model)

```

Since the estimate for passenger class is negative, we can say that odds of survival decrease as a passenger's class increases. 

Now, let's focus on predicting survival. How can I make the best model at predicting passenger survival based on the variables I have? - "How can I write a predictive model passenger survival on the titanic using the titanic_train data from the titanic package?"

```{r}

set.seed(123)  # Set random seed for reproducibility
train_indices <- sample(1:nrow(titanic_train), nrow(titanic_train)*0.7)  # 70% for training
train_data <- titanic_train[train_indices, ]
test_data <- titanic_train[-train_indices, ]

# Fit a logistic regression model
model <- glm(Survived ~ Pclass + Sex + Age + Fare,
             data = train_data,
             family = binomial)

# Make predictions on the test set
pred <- predict(model, newdata = test_data, type = "response")

# Convert probabilities to binary (1 for survival, 0 for non-survival)
pred_binary <- ifelse(pred > 0.5, 1, 0)

# Evaluate the model performance
accuracy <- sum(pred_binary == test_data$Survived) / length(test_data$Survived)

### OWN CODE
pred_binary.v2 <- pred_binary[which(!is.na(pred_binary))]
true_survived  <- test_data$Survived[which(!is.na(pred_binary))]
accuracy       <- sum(pred_binary.v2 == true_survived) / length(true_survived)

summary(model)
accuracy

```

That is one model, but now I want to do variable selection so that I have the most predictive model possible. - "How to do variable selection for modelling passenger survival on the titanic using the titanic_train data from the titanic package?"

Step 1: Univariate analysis
Step 2: Correlation analysis
Step 3: Step-wise selection

Let's do step one for numeric variables - "How do I test for a statistical association between a numeric and a binary variable?"

```{r}

str(titanic_train)

t.test(titanic_train$Age ~ titanic_train$Survived)
wilcox.test(titanic_train$SibSp ~ titanic_train$Survived)
wilcox.test(titanic_train$Parch ~ titanic_train$Survived)
t.test(titanic_train$Fare ~ titanic_train$Survived)

```

Now let's look at our categorical variables. "How do I test for a statistical association between two categorical variables?"

```{r}

str(titanic_train)

chisq.test(table(titanic_train$Survived, as.factor(titanic_train$Pclass)))
chisq.test(table(titanic_train$Survived, as.factor(titanic_train$Sex)))
chisq.test(table(titanic_train$Survived, as.factor(titanic_train$Embarked)))

```

Great, let's move on to step 2: correlation analysis. - "How do I check for correlation between predictor variables for logistic regression?"

```{r}

cor(titanic_train[complete.cases(titanic_train), c("Age", "SibSp", "Parch", "Fare")])

```

Now that we have a list of possible predictors, we are ready to move on to actually selecting variables and creating a final model. - "How do I do stepwise logistic regression?"

```{r}

# Create a logistic regression model using all predictor variables
full_model <- glm(Survived ~ as.factor(Pclass) + as.factor(Sex) + Age + SibSp + Parch + Fare + as.factor(Embarked), 
                  data = titanic_train, family = "binomial")

# Perform stepwise logistic regression
stepwise_model <- step(full_model, direction = "both")

summary(stepwise_model)

```

Finally, lets create a table showing the odds ratios and 95% confidence intervals of our final model. - "Create a table of odds ratios and 95% confidence interval from logistic regression"

```{r}

# Obtain odds ratios and confidence intervals
odds_ratios <- exp(coef(stepwise_model))
conf_intervals <- exp(confint(stepwise_model))

# Combine odds ratios and confidence intervals into a table
results_table <- cbind(odds_ratios, conf_intervals)
results_table

```


## Challenge Problem

You will be using the CalCOFI data to model the association between water temperature and salinity. The full dataset comes from here - https://www.kaggle.com/datasets/sohier/calcofi?resource=download, but for today, you will be using a cross-sectional piece of the data from 2016.

Context on the data:
"The CalCOFI data set represents the longest (1949-present) and most complete (more than 50,000 sampling stations) time series of oceanographic and larval fish data in the world. It includes abundance data on the larvae of over 250 species of fish; larval length frequency data and egg abundance data on key commercial species; and oceanographic and plankton data. The physical, chemical, and biological data collected at regular time and space intervals quickly became valuable for documenting climatic cycles in the California Current and a range of biological responses to them. CalCOFI research drew world attention to the biological response to the dramatic Pacific-warming event in 1957-58 and introduced the term “El Niño” into the scientific literature.

The California Cooperative Oceanic Fisheries Investigations (CalCOFI) are a unique partnership of the California Department of Fish & Wildlife, NOAA Fisheries Service and Scripps Institution of Oceanography. The organization was formed in 1949 to study the ecological aspects of the sardine population collapse off California. Today our focus has shifted to the study of the marine environment off the coast of California, the management of its living resources, and monitoring the indicators of El Nino and climate change. CalCOFI conducts quarterly cruises off southern & central California, collecting a suite of hydrographic and biological data on station and underway. Data collected at depths down to 500 m include: temperature, salinity, oxygen, phosphate, silicate, nitrate and nitrite, chlorophyll, transmissometer, PAR, C14 primary productivity, phytoplankton biodiversity, zooplankton biomass, and zooplankton biodiversity."

Further information about each of the columns can be found here - https://calcofi.com/index.php?option=com_content&view=article&id=77:database-tables&catid=73&Itemid=993. Note that many columns have been removed in your version of the dataset due to time constraints.

Your job is to determine the association between water temperature (X, column name T_degC) in degrees celcius and water salinity (Y, column name Salnty) in g/kg. Consider potential confounders and effect modifiers, and check the assumptions of your model. Also create a visualization for the relationship.

```{r}

# read in the data
cofi <- read.csv("CalCOFI_2016.csv")
summary(cofi)

```


